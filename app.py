import os
import os.path
import html
from typing import Tuple

import streamlit as st
import torch
from transformers import BertTokenizer, BartForConditionalGeneration

# å¯é€‰ï¼šå°è¯•å¯¼å…¥å¤§æ¨¡å‹è°ƒç”¨å‡½æ•°ï¼ˆè‹¥æœªå®‰è£…ç›¸å…³ä¾èµ–ï¼ŒUI ä»å¯æ­£å¸¸è¿è¡Œï¼‰
LLM_AVAILABLE = True
LLM_IMPORT_ERROR = ""
try:
    from utils.invoke_llm import invoke_llm as llm_summarize
except Exception as e:
    LLM_AVAILABLE = False
    LLM_IMPORT_ERROR = str(e)

# ==== è·¯å¾„è®¾ç½® ====
MODEL_PATH = os.path.abspath('./results/checkpoint-8500')

# ==== åŠ è½½ tokenizer å’Œæ¨¡å‹ ====
@st.cache_resource  # é¿å…æ¯æ¬¡é‡æ–°åŠ è½½
def load_model() -> Tuple[BertTokenizer, BartForConditionalGeneration, str]:
    tokenizer = BertTokenizer.from_pretrained(MODEL_PATH)
    model = BartForConditionalGeneration.from_pretrained(MODEL_PATH)
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model.to(device)
    return tokenizer, model, device

tokenizer, model, device = load_model()

# ==== æ¨ç†å‡½æ•° ====
@st.cache_data(show_spinner=False)
def tokenize_inputs(text: str, max_input_length: int):
    return tokenizer(
        text,
        return_tensors="pt",
        truncation=True,
        padding="max_length",
        max_length=max_input_length,
    )


def generate_summary(
    text: str,
    max_input_length: int = 512,
    max_output_length: int = 128,
    min_output_length: int = 10,
    num_beams: int = 4,
    remove_spaces: bool = True,
) -> str:
    inputs = tokenize_inputs(text, max_input_length)
    input_ids = inputs["input_ids"].to(device)
    attention_mask = inputs["attention_mask"].to(device)

    outputs = model.generate(
        input_ids=input_ids,
        attention_mask=attention_mask,
        max_length=max_output_length,
        min_length=min_output_length,
        num_beams=num_beams,
        early_stopping=True,
    )

    summary = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]
    return summary.replace(" ", "") if remove_spaces else summary


# ==== UI å…¨å±€è®¾ç½®ä¸æ ·å¼ ====
st.set_page_config(page_title="æ–‡æœ¬æ‘˜è¦å·¥å…·", page_icon="ğŸ“", layout="wide")

# ä¸»é¢˜è‡ªé€‚åº”çš„ç¾åŒ–æ ·å¼ï¼ˆå…¼å®¹æµ…è‰²/æ·±è‰²ä¸»é¢˜ï¼‰
st.markdown(
    """
    <style>
      .block-container { padding-top: 1rem; }
      .stTextArea textarea { font-size: 14px; line-height: 1.6; }
      .result-box { padding: 1rem; border-radius: 8px; border: 1px solid; }
      .summary-text { white-space: pre-wrap; line-height: 1.7; font-size: 15px; }
      .tip { font-size: 13px; }
      .ok-badge, .err-badge { display:inline-block; padding:2px 8px; border-radius:999px; border:1px solid; font-size:12px; margin-left:8px; background: transparent; }
      .ok-badge { border-color: #22c55e; color: #22c55e; }
      .err-badge { border-color: #ef4444; color: #ef4444; }

      /* --- st.radio ä¼ªè£…æˆ st.tabs çš„æ ·å¼ --- */
      /* éšè— radio ç»„ä»¶çš„æ ‡é¢˜ */
      div[data-testid="stRadio"] > label[data-testid="stWidgetLabel"] { display: none; }
      /* radio å®¹å™¨ï¼Œæ¨¡æ‹Ÿ tab æ çš„åº•éƒ¨è¾¹æ¡† */
      div[data-testid="stRadio"] > div[role="radiogroup"] {
          border-bottom: 1px solid rgba(49, 51, 63, 0.2);
          margin-bottom: 1.5rem;
          padding-bottom: 0;
      }
      /* å•ä¸ª radio é€‰é¡¹ï¼Œæ¨¡æ‹Ÿ tab æŒ‰é’® */
      div[data-testid="stRadio"] > div > label {
          background-color: transparent !important;
          border: none !important;
          padding: 0.5rem 0.1rem;
          margin: 0 1.5rem 0 0;
          border-bottom: 3px solid transparent;
          transition: border-color 0.2s ease-in-out;
          border-radius: 0;
      }
      /* é€‰ä¸­çš„ radio é€‰é¡¹ï¼Œæ¨¡æ‹Ÿæ¿€æ´»çš„ tab */
      div[data-testid="stRadio"] > div > label[aria-checked="true"] {
          font-weight: 600;
          border-bottom-color: var(--primary-color);
          color: var(--text-color);
      }
      /* éšè—åŸå§‹çš„ radio å°åœ†åœˆ */
      div[data-testid="stRadio"] input[type="radio"] { display: none; }

      /* æµ…è‰²ä¸»é¢˜ï¼ˆé»˜è®¤ï¼‰ */
      @media (prefers-color-scheme: light) {
        .stTextArea textarea { background: #ffffff; color: #111827; }
        .result-box { background: #f7f9fc; color: #111827; border-color: #e6eaf2; box-shadow: inset 0 1px 2px rgba(0,0,0,0.04); }
        .tip { color: #6b7280; }
      }

      /* æ·±è‰²ä¸»é¢˜ */
      @media (prefers-color-scheme: dark) {
        .stTextArea textarea { background: #111827; color: #e5e7eb; }
        .result-box { background: #0b1220; color: #e5e7eb; border-color: #2a3441; box-shadow: inset 0 1px 2px rgba(255,255,255,0.04); }
        .tip { color: #94a3b8; }
      }
    </style>
    """,
    unsafe_allow_html=True,
)

# ==== ä¼šè¯çŠ¶æ€åˆå§‹åŒ– ====
# ç¡®ä¿æ–‡æœ¬åŒºåŸŸçš„ key åœ¨ session_state ä¸­å­˜åœ¨
if "local_text_area" not in st.session_state:
    st.session_state.local_text_area = ""
if "llm_text_area" not in st.session_state:
    st.session_state.llm_text_area = ""
if "local_summary" not in st.session_state:
    st.session_state.local_summary = ""
if "llm_summary" not in st.session_state:
    st.session_state.llm_summary = ""


# ==== å›è°ƒå‡½æ•° ====
def clear_text_area(key: str):
    """æ¸…ç©ºæŒ‡å®š key å¯¹åº”çš„ session_state ä¸­çš„æ–‡æœ¬ã€‚"""
    if key in st.session_state:
        st.session_state[key] = ""

st.title("ğŸ“ æ–‡æœ¬æ‘˜è¦å·¥å…·")

with st.container():
    cols = st.columns([1, 1, 1])
    with cols[0]:
        st.markdown("è®¾å¤‡çŠ¶æ€ï¼š" + ("GPU å¯ç”¨ âœ…" if torch.cuda.is_available() else "CPU è¿è¡Œä¸­"))
    with cols[1]:
        st.markdown(
            f"æœ¬åœ°æ¨¡å‹è·¯å¾„ï¼š`{MODEL_PATH}`"
        )
    with cols[2]:
        if LLM_AVAILABLE:
            st.markdown("å¤§æ¨¡å‹ä¾èµ–ï¼š<span class=\"ok-badge\">å¯ç”¨</span>", unsafe_allow_html=True)
        else:
            st.markdown(
                "å¤§æ¨¡å‹ä¾èµ–ï¼š<span class=\"err-badge\">ä¸å¯ç”¨</span>",
                unsafe_allow_html=True,
            )
            with st.expander("æŸ¥çœ‹é”™è¯¯è¯¦æƒ…"):
                st.code(LLM_IMPORT_ERROR)

st.markdown("---")

# ä¾§è¾¹æ å‚æ•°ï¼ˆä¾¿äºè°ƒå‚ï¼‰
st.sidebar.header("å‚æ•°è®¾ç½®")
with st.sidebar:
    st.subheader("æœ¬åœ°æ¨¡å‹å‚æ•°")
    max_input_length = st.slider("æœ€å¤§è¾“å…¥é•¿åº¦", min_value=64, max_value=1024, value=512, step=16)
    max_output_length = st.slider("æœ€å¤§æ‘˜è¦é•¿åº¦", min_value=16, max_value=256, value=128, step=8)
    min_output_length = st.slider("æœ€å°æ‘˜è¦é•¿åº¦", min_value=1, max_value=64, value=10, step=1)
    num_beams = st.slider("Beam Size", min_value=1, max_value=8, value=4, step=1)
    remove_spaces = st.checkbox("ç§»é™¤è¾“å‡ºä¸­çš„ç©ºæ ¼ï¼ˆé€‚åˆä¸­æ–‡ï¼‰", value=True)

    st.subheader("å¤§æ¨¡å‹è®¾ç½®")
    st.caption("åœ¨ .env ä¸­é…ç½® CUSTOM_MODEL / API_BASE / CUSTOM_API_KEY")

# ä¸¤éƒ¨åˆ† UIï¼šæˆ‘ä»¬çš„æ¨¡å‹æ‘˜è¦ + å¤§æ¨¡å‹æ‘˜è¦
# ä½¿ç”¨åŸç”Ÿ st.tabsï¼Œå¹¶é€šè¿‡ session_state ä¿ç•™è¾“å…¥ä¸è¾“å‡º
tab1, tab2 = st.tabs(["æˆ‘ä»¬çš„æ¨¡å‹è¿›è¡Œæ‘˜è¦", "å¤§æ¨¡å‹è¿›è¡Œæ‘˜è¦"])

st.markdown("---")


with tab1:
    st.subheader("âœ‚ï¸ ä½¿ç”¨æˆ‘ä»¬çš„æœ¬åœ°æ¨¡å‹è¿›è¡Œæ‘˜è¦")
    st.markdown("è¾“å…¥æ–‡æœ¬æˆ–ä¸Šä¼  .txt æ–‡ä»¶ï¼Œç‚¹å‡»æŒ‰é’®ç”Ÿæˆæ‘˜è¦ã€‚")

    input_option = st.radio("é€‰æ‹©è¾“å…¥æ–¹å¼ï¼š", ("æ‰‹åŠ¨è¾“å…¥æ–‡æœ¬", "ä¸Šä¼ æ–‡æœ¬æ–‡ä»¶"), key="local_input_option")

    if input_option == "æ‰‹åŠ¨è¾“å…¥æ–‡æœ¬":
        st.text_area("åœ¨æ­¤è¾“å…¥æ–‡æœ¬ï¼š", height=220, key="local_text_area")
    else:
        uploaded_file_local = st.file_uploader("ä¸Šä¼ æ–‡æœ¬æ–‡ä»¶ (.txt)", type=["txt"], key="local_uploader")
        if uploaded_file_local is not None:
            try:
                text_content = uploaded_file_local.read().decode("utf-8")
            except Exception:
                text_content = uploaded_file_local.read().decode("utf-8", errors="ignore")
            # å°†æ–‡ä»¶å†…å®¹åŠ è½½åˆ°ä¼šè¯çŠ¶æ€ä¸­ï¼Œå¹¶ç”¨äºé¢„è§ˆ
            st.session_state.local_text_area = text_content
            st.text_area("æ–‡ä»¶å†…å®¹é¢„è§ˆï¼š", value=st.session_state.local_text_area, height=220, key="local_file_preview", disabled=True)

    cols = st.columns([1, 1])
    with cols[0]:
        gen_local = st.button("ç”Ÿæˆæ‘˜è¦", type="primary", key="btn_local_gen")
        with cols[1]:
            st.button("æ¸…ç©ºè¾“å…¥", key="btn_local_clear", on_click=clear_text_area, args=("local_text_area",))

    if gen_local:
        # ä» session_state è·å–æœ€æ–°çš„æ–‡æœ¬å†…å®¹
        text_to_summarize = st.session_state.get("local_text_area", "").strip()
        if not text_to_summarize:
            st.warning("è¯·è¾“å…¥æ–‡æœ¬æˆ–ä¸Šä¼ æ–‡ä»¶ï¼")
        else:
            with st.spinner("æ­£åœ¨ä½¿ç”¨æœ¬åœ°æ¨¡å‹ç”Ÿæˆæ‘˜è¦ï¼Œè¯·ç¨å€™..."):
                st.session_state.local_summary = generate_summary(
                    text_to_summarize,
                    max_input_length=max_input_length,
                    max_output_length=max_output_length,
                    min_output_length=min_output_length,
                    num_beams=num_beams,
                    remove_spaces=remove_spaces,
                )

    # å§‹ç»ˆæ¸²æŸ“å·²å­˜åœ¨çš„æ‘˜è¦
    if st.session_state.get("local_summary"):
        st.subheader("ğŸ“„ æ‘˜è¦ç»“æœï¼ˆæœ¬åœ°æ¨¡å‹ï¼‰")
        st.markdown(f"<div class='result-box'><div class='summary-text'>{html.escape(st.session_state.local_summary)}</div></div>", unsafe_allow_html=True)


with tab2:
    st.subheader("ğŸ¤– ä½¿ç”¨å¤§æ¨¡å‹è¿›è¡Œæ‘˜è¦")
    if not LLM_AVAILABLE:
        st.error("å½“å‰ç¯å¢ƒæœªå®‰è£…æˆ–æœªæ­£ç¡®é…ç½®å¤§æ¨¡å‹ä¾èµ–ï¼ˆlangchain_openai/ç¯å¢ƒå˜é‡ï¼‰ã€‚è¯·æ£€æŸ¥ .env è®¾ç½®ä¸ä¾èµ–å®‰è£…ã€‚")
        st.stop()

    st.markdown("è¾“å…¥æ–‡æœ¬æˆ–ä¸Šä¼  .txt æ–‡ä»¶ï¼Œç‚¹å‡»æŒ‰é’®è°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œé«˜è´¨é‡æ‘˜è¦ã€‚")
    input_option_llm = st.radio("é€‰æ‹©è¾“å…¥æ–¹å¼ï¼š", ("æ‰‹åŠ¨è¾“å…¥æ–‡æœ¬", "ä¸Šä¼ æ–‡æœ¬æ–‡ä»¶"), key="llm_input_option")

    if input_option_llm == "æ‰‹åŠ¨è¾“å…¥æ–‡æœ¬":
        st.text_area("åœ¨æ­¤è¾“å…¥æ–‡æœ¬ï¼š", height=220, key="llm_text_area")
    else:
        uploaded_file_llm = st.file_uploader("ä¸Šä¼ æ–‡æœ¬æ–‡ä»¶ (.txt)", type=["txt"], key="llm_uploader")
        if uploaded_file_llm is not None:
            try:
                text_content = uploaded_file_llm.read().decode("utf-8")
            except Exception:
                text_content = uploaded_file_llm.read().decode("utf-8", errors="ignore")
            st.session_state.llm_text_area = text_content
            st.text_area("æ–‡ä»¶å†…å®¹é¢„è§ˆï¼š", value=st.session_state.llm_text_area, height=220, key="llm_file_preview", disabled=True)

    cols2 = st.columns([1, 1])
    with cols2[0]:
        gen_llm = st.button("è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆæ‘˜è¦", type="primary", key="btn_llm_gen")
    with cols2[1]:
        st.button("æ¸…ç©ºè¾“å…¥", key="btn_llm_clear", on_click=clear_text_area, args=("llm_text_area",))

    # ç¯å¢ƒå˜é‡æç¤º
    env_model = os.environ.get("CUSTOM_MODEL")
    env_base = os.environ.get("API_BASE")
    env_key = os.environ.get("CUSTOM_API_KEY")
    st.caption(
        f"å½“å‰å¤§æ¨¡å‹é…ç½®ï¼šmodel={env_model or 'æœªè®¾ç½®'} | base={env_base or 'æœªè®¾ç½®'} | key={'å·²é…ç½®' if env_key else 'æœªè®¾ç½®'}"
    )

    if gen_llm:
        text_to_summarize_llm = st.session_state.get("llm_text_area", "").strip()
        if not text_to_summarize_llm:
            st.warning("è¯·è¾“å…¥æ–‡æœ¬æˆ–ä¸Šä¼ æ–‡ä»¶ï¼")
        else:
            with st.spinner("æ­£åœ¨è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆæ‘˜è¦ï¼Œè¯·ç¨å€™..."):
                try:
                    st.session_state.llm_summary = llm_summarize(text_to_summarize_llm)
                except Exception as e:
                    st.error(f"è°ƒç”¨å¤§æ¨¡å‹å¤±è´¥ï¼š{e}")
                    st.session_state.llm_summary = ""

    # å§‹ç»ˆæ¸²æŸ“å·²å­˜åœ¨çš„æ‘˜è¦
    if st.session_state.get("llm_summary"):
        st.subheader("ğŸ“„ æ‘˜è¦ç»“æœï¼ˆå¤§æ¨¡å‹ï¼‰")
        st.markdown(f"<div class='result-box'><div class='summary-text'>{html.escape(st.session_state.llm_summary)}</div></div>", unsafe_allow_html=True)

